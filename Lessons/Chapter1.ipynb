{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be9c6659",
   "metadata": {},
   "source": [
    "# Machine Learning Taxonomy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da234b8c",
   "metadata": {},
   "source": [
    "In Machine learning have two main types of taxonomy:\n",
    "\n",
    "### Taxonomy by Supervision (The \"How\")\n",
    "\n",
    "- ### Supervised Learning\n",
    "  - We're provided with labeled data to train on.\n",
    "  - We wish to learn to predict from the corresponding set of labels on new samples.\n",
    "  - We usually do this using Regression or Classification based on the label type.\n",
    "- ### Unsupervised Learning \n",
    "  - The data we're provided contains no labels.\n",
    "  - We aim to discover structural/spacial relations based on the data.\n",
    "  - Common tasks: Clustering (K-means), Dimensionality Reduction, Association\n",
    "\n",
    "- ### Semi-Supervised Learning\n",
    "  - Some of the data we're provided is labeled or most of the data isn't labeled.\n",
    "  - The general task is for the model to be able to label to full data-set otherwise known as self-training\n",
    "  - We apply similar or hybrid solutions to general approach described above.\n",
    "  \n",
    "- ### Self-Supervised Learning\n",
    "  - The task is designed so that the data is its own label\n",
    "  - There's no need for human annotation.\n",
    "  - We aim to teach a model to extract the useful features of the data provided.\n",
    "  - Only later on in the modelling would we use this pre-trained model for specific tasks\n",
    "\n",
    "### Taxonomy by Model Objective (The \"What\")\n",
    "\n",
    "Regardless of the supervision above, the model will usually fall into one of the following buckets:\n",
    "\n",
    "- ### Discriminative Models\n",
    "  - Focus on mapping inputs to outputs directly\n",
    "  - Example: Provide an image with a dog and the model classifies the image as a dog from a cat/dog label set\n",
    "- ### Generative Models\n",
    "  - Focus on understanding how the data was \"made\"\n",
    "  - Example: Provide an \"Empty Matrix\" and then model outputs an image of a dog <br> from a pool of images of different dogs and cats it can create"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120953f1",
   "metadata": {},
   "source": [
    "# Supervised Learning \n",
    "\n",
    "We now dive into the main concepts that are applied in supervised learning since these are the foundamental blocks that are used repetatively throughout Deep Learning (no matter the complexity of the model).\n",
    "\n",
    "Supervised learning can summarised as a model the produces a mathematical function, such that when pass through inputs to the function it'll compute the the output, where the output is referred as the $\\color{lightblue}inference$.\n",
    "\n",
    "This function contains $\\color{lightblue}parameter$, which affect the output from a given input. As such the model equation described a family of possible relationships between inputs and outputs, where the parameters specifiy the particular relationship.\n",
    "\n",
    "$\\color{lightblue}training$ a model essentially means trying to find the parameters that describe the true relationship between the inputs and output. \n",
    "\n",
    "We train the model by following a procedure of trial and error over the training set where for each trial measure the error and then correct the parameters in the direction that will reduce the error in the next run of trials and errors.\n",
    "\n",
    "After training a model, we asses its performance; we run themodel on a seperate test data to see how well it performs or how well it $\\color{lightblue}generalises$\n",
    "\n",
    "If the results are good enough then the model is ready for deployment\n",
    "\n",
    "#### Formalization\n",
    "\n",
    "$\\text{Let } \\vec x \\in \\R^n \\text{ be our input and } \\vec y \\in \\R^m  \\text{ be the output}$\n",
    "\n",
    "$\\text{To make a prediction we need a model } f[•] \\text{ which takes x and returns y}$\n",
    "\n",
    "$$ f[x]= y $$\n",
    "\n",
    "$\\text{Since we need parameters to describe the relation then } f \\text{ needs to accept these parameters } \\phi \\text{ therefore:}$ \n",
    "\n",
    "$$ f[x, \\phi] = y$$\n",
    "\n",
    "$\\text{To train the model we quantify the degree of mismatch between the inference and the true values:}$\n",
    "\n",
    "$$ \\hat\\phi = \\argmin_{\\phi}\\left[L[\\phi]\\right] = \\argmin_{\\phi}\\left[L[\\{x_i, y_i\\}, \\phi]\\right]  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cf9dee",
   "metadata": {},
   "source": [
    "## 1D Linear Regression Model Example\n",
    "\n",
    "Assume our input and output are scalar values\n",
    "\n",
    "$\\text{model: }$  $$y = f[x, \\phi] = \\phi_0 + \\phi_1x$$\n",
    "\n",
    "$\\text{Parameters: }$  $$\\phi = [\\phi_0, \\phi_2]$$\n",
    "\n",
    "$\\text{Loss Function: }$ $$L[\\phi] = \\sum_{i=1}^N(f[x_i, \\phi] - y_i)^2 = \\sum_{i=1}^N(\\phi_0 + \\phi_1x - y_i)^2$$\n",
    "\n",
    "The following link provides a visualization of the parameters and it's effect on the Loss function\n",
    "\n",
    "\n",
    "$\\text{Our Goal: }$ $$\\hat\\phi = \\argmin_{\\phi} \\left[\\sum_{i=1}^N(\\phi_0+\\phi_1x - y_i)^2\\right]$$\n",
    "\n",
    "The following link provides a visualization of the above concepts:\n",
    "1. 1D linear model\n",
    "2. Least Square loss Function\n",
    "3. Loss function space with respect to parameters\n",
    "\n",
    "https://udlbook.github.io/udlfigures/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c924886a",
   "metadata": {},
   "source": [
    "## Extending Linear Regression to higher Dimension\n",
    "\n",
    "Suppose we have d features $x = (x_1, x_2, ..., x_d)$\n",
    "\n",
    "The general structure remains the same, from a mathematical and implementation stand point we now represent this using vectors and vector operation.\n",
    "\n",
    "$\\text{model: }$ $$y = f[x, \\phi] = \\phi_0 + \\sum_{i=1}^dx_i\\phi_i =  \\phi^Tx$$\n",
    "\n",
    "$\\text{Parameters: }$ $$\\phi = [\\phi_0, \\, \\phi_1, \\dots, \\phi_d]$$\n",
    "\n",
    "If this applies to a single instance then we can apply to a subset of the training data and this can be represented by:\n",
    "\n",
    "$$\n",
    "X = \\begin{bmatrix}\n",
    "— & x_1 & — \\\\\n",
    "— & x_2 & — \\\\\n",
    "— & x_3 & — \\\\\n",
    " & \\vdots & \\\\\n",
    "— & x_N & — \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Where each $x_{i} \\in \\R^d$ that is a row vector containing d-values representing the d-features the inference would be: \n",
    "\n",
    "$$ \n",
    "f[X, \\phi]  = X\\begin{bmatrix} \\phi_1 \\\\ \\phi_2 \\\\ \\vdots \\\\ \\phi_d \\end{bmatrix} + \\phi_0\n",
    "\\begin{bmatrix} \n",
    "1 \\\\ 1 \\\\ \\vdots \\\\ 1 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "We also present what's happening for a dimension perspective\n",
    "$$\n",
    "\n",
    "(N \\times 1) = (N \\times d) (d \\times 1) + (N \\times 1)\n",
    "$$\n",
    "\n",
    "$\\text{Loss Function: }$ $$L[\\phi] = \\frac{1}{2N}\\sum_{i=1}^N(f[X, \\phi] - y)^2  = \\frac{1}{2N} ||f[X, \\phi] - y||^2$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfbfb8c",
   "metadata": {},
   "source": [
    "### Questions Remained to be answered: \n",
    "1. The current model would only perform well on linear data, what if the data isn't linearly correlated?\n",
    "2. Whe haven't yet described the method to improve the parameters?\n",
    "3. How did we come up with the this loss function and how do we know it's a good loss to use?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
