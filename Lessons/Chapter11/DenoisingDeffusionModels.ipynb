{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6de2b175",
   "metadata": {},
   "source": [
    "# Denoising Diffusion Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca0bba0",
   "metadata": {},
   "source": [
    "To Denoise Diffusion consists of two processes: \n",
    "1. **Forward Diffusion process** - Gradually add noise to the input\n",
    "2. **Reverse denoising process** - Learns to generate data by denoising"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ea9052",
   "metadata": {},
   "source": [
    "Given an observed training data x. Assume the data is governed by some unobserved latent random variable $\\mathbf{z}$.\n",
    "To generate consists of two steps: \n",
    "1. A **latent value** of $\\mathbf{z}$ is generated from some prior distribution $p(z)$.\n",
    "2. An **observed value** is generated from a conditional distribution $p( \\mathbf{x} | \\mathbf{z})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425c2bcf",
   "metadata": {},
   "source": [
    "## Preliminaries for Denoising Diffusion Probabilistic Models (DDPM)\n",
    "\n",
    "|Concept | Summary | \n",
    "|--------|---------|\n",
    "| **Markov Chain** | $$p(x_{t+1} \\|x_t, \\dots x_1) = p(x_{t+1} \\| x_t)$$ |\n",
    "| **Latent Value of $\\mathbf{z}$** | This is generated from some prior distribution $p(\\mathbf{z})$ |\n",
    "| **observed value** | This is generated from a conditional distribution $p(\\mathbf{x} \\| \\mathbf{z})$ |\n",
    "| **Marginal-Likelihood/Evidence** | $$p(\\mathbf{x}) = \\int p(\\mathbf{z})p(\\mathbf{x} \\| \\mathbf{z}) d\\mathbf{z}$$ |\n",
    "| **Posterior** | $$p(\\mathbf{z} \\| \\mathbf{x}) = \\frac{p(\\mathbf{z}) \\cdot p(\\mathbf{x} \\| \\mathbf{z})}{p(\\mathbf{x})}$$ |\n",
    "\n",
    "To obtain the **Posterior** is very difficult due to high-dimensional intergeration in the denominator. \n",
    "\n",
    "As such we use another method: **Variational Inference**\n",
    "\n",
    "We use a simpler Distribution $\\mathbf{q}_{\\phi}(\\mathbf{z} | \\mathbf{x})$ to approximate the **True Posterior**.\n",
    "\n",
    "So our goal is to find a distribution simple enough for us that is tractable, but close enough to the true distribution. \n",
    "\n",
    "To measure the difference in these distribution we use the $$\\text{argmin}_{\\phi} D_{KL} \\left(\\mathbf{q}_{\\phi}(\\mathbf{z} | \\mathbf{x}) || p(\\mathbf{z} \\| \\mathbf{x}) \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f3e9fa",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "&\\textbf{Denoising Diffusion Probabilistic Models (DDPM)} \\\\\n",
    "\\\\\n",
    "&\\textbf{1. Forward Process (Adding Noise):} \\\\\n",
    "&q(x_t | x_{t-1}) = \\mathcal{N}(x_t; \\sqrt{1 - \\beta_t} x_{t-1}, \\beta_t \\mathbf{I}) \\\\\n",
    "&x_t = \\sqrt{\\bar{\\alpha}_t} x_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, \\mathbf{I}) \\quad (\\text{where } \\bar{\\alpha}_t = \\prod_{s=1}^t (1 - \\beta_s)) \\\\\n",
    "\\\\\n",
    "&\\textbf{2. Reverse Process (Denoising):} \\\\\n",
    "&p_\\theta(x_{t-1} | x_t) = \\mathcal{N}(x_{t-1}; \\mu_\\theta(x_t, t), \\Sigma_\\theta(x_t, t)) \\\\\n",
    "\\\\\n",
    "&\\textbf{3. Simplified Objective Function:} \\\\\n",
    "&L_{\\text{simple}}(\\theta) = \\mathbb{E}_{t, x_0, \\epsilon} \\left[ \\| \\epsilon - \\epsilon_\\theta(\\sqrt{\\bar{\\alpha}_t} x_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\epsilon, t) \\|^2 \\right] \\\\\n",
    "\\\\\n",
    "&\\textbf{4. Sampling Step (Iterative Denoising):} \\\\\n",
    "&x_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}} \\left( x_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\epsilon_\\theta(x_t, t) \\right) + \\sigma_t z \\quad \\text{where } z \\sim \\mathcal{N}(0, \\mathbf{I})\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8668ae",
   "metadata": {},
   "source": [
    "### Training Algorithm for Denoising Diffusion Probabilistic Models (DDPM)\n",
    "\n",
    "**1. Forward Process (Adding Noise):**\n",
    "- For each training sample $x_0$:\n",
    "  - For $t = 1$ to $T$:\n",
    "    - Sample noise $\\epsilon \\sim \\mathcal{N}(0, \\mathbf{I})$\n",
    "    - Generate noisy data: $x_t = \\sqrt{\\bar{\\alpha}_t} x_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\epsilon$\n",
    "\n",
    "**2. Training Objective:**\n",
    "- Train a neural network $\\epsilon_\\theta(x_t, t)$ to predict the noise $\\epsilon$ added at each step.\n",
    "- Minimize the loss:\n",
    "  $$\n",
    "  L_{\\text{simple}}(\\theta) = \\mathbb{E}_{t, x_0, \\epsilon} \\left[ \\| \\epsilon - \\epsilon_\\theta(x_t, t) \\|^2 \\right]\n",
    "  $$\n",
    "\n",
    "**3. Training Steps:**\n",
    "- For each batch:\n",
    "  1. Sample $x_0$ from the dataset.\n",
    "  2. Randomly choose $t$ (noise level).\n",
    "  3. Sample noise $\\epsilon$.\n",
    "  4. Compute $x_t$ using the forward process.\n",
    "  5. Predict noise: $\\hat{\\epsilon} = \\epsilon_\\theta(x_t, t)$.\n",
    "  6. Compute and backpropagate the loss.\n",
    "\n",
    "**Summary:**  \n",
    "The model learns to reverse the noise process by predicting the noise at each step, enabling generation by iterative denoising.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea04456",
   "metadata": {},
   "source": [
    "### Sampling Algorithm for Denoising Diffusion Probabilistic Models (DDPM)\n",
    "\n",
    "**1. Start with pure noise:**  \n",
    "- Initialize $x_T \\sim \\mathcal{N}(0, \\mathbf{I})$ (random noise).\n",
    "\n",
    "**2. Iterative Denoising:**  \n",
    "- For $t = T$ down to $1$:\n",
    "  - Predict noise: $\\hat{\\epsilon}_\\theta(x_t, t)$ using the trained model.\n",
    "  - Compute mean: $\\mu_\\theta(x_t, t)$ (formula depends on DDPM implementation).\n",
    "  - Sample $z \\sim \\mathcal{N}(0, \\mathbf{I})$ (if $t > 1$; else $z = 0$).\n",
    "  - Update:  \n",
    "    $$\n",
    "    x_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}} \\left( x_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\hat{\\epsilon}_\\theta(x_t, t) \\right) + \\sigma_t z\n",
    "    $$\n",
    "\n",
    "**3. Output:**  \n",
    "- $x_0$ is the generated sample (e.g., image).\n",
    "\n",
    "**Summary:**  \n",
    "Start from random noise and iteratively denoise using the learned model to generate a realistic sample."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
