{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fbcb63d",
   "metadata": {},
   "source": [
    "# Loss functions\n",
    "\n",
    "In chapter 1 we discussed how in supervised learning we derive a function which aims to predict an output based on an input, <br> We measure the ability of this function/model to produce good results by a loss function. <br>\n",
    "We discussed that this Loss measures how far off the predicted result was from the true result.\n",
    "\n",
    "We went through the classic linear regression example where the loss function was the $\\text{ mean square error}$.<br> At the end of the chapter we asked why we used this formula? what makes a good loss function? how do we choose our loss function?\n",
    "\n",
    "In this chapter we'll:\n",
    "1. Justify the use of this function in Linear regression \n",
    "2. Present a method for choosing a loss function based on a provided learning problem. \n",
    "3. Go through a few common learning problems to apply the method to and see the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bd4367",
   "metadata": {},
   "source": [
    "### Definition of the Loss \n",
    "\n",
    "$$\\boxed{\\text{Loss function := } L \\ : \\ \\mathbb{R}^{N \\times K} \\times \\mathbb{R}^{N \\times K} \\rightarrow \\mathbb{R}}$$\n",
    "\n",
    "The above is a formal description though it's usually seen as follows: \n",
    "\n",
    "$$\\boxed{L[\\phi] = L[f(x_i, \\phi), y_i] \\in \\mathbb{R}}$$\n",
    "\n",
    "It's a description of the **missmatch** between the model predictions, $f[x_i, \\phi]$ and the ground-truth outputs $y_i$<br>\n",
    "NOTE: That we provide the shorthand \"$L[\\phi]$\" since this function is with respect to the parameters meaning $\\phi$ is the only thing we can change and thus truely what we're trying to measure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a1e549",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "---\n",
    "---\n",
    "\n",
    "# Probability Recap \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f2fa10",
   "metadata": {},
   "source": [
    "## Basic Definitions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4feecaf3",
   "metadata": {},
   "source": [
    "\n",
    "**NOTE: This assumes background knowledge**\n",
    "\n",
    "Before moving on, we'll go over a few main notions that'll help us along the way for deriving loss functions. \n",
    "\n",
    "$\\text{Probability Space:= is a 3-tuple model } (\\Omega, F, P)$\n",
    "\n",
    "$ \\Omega : \\text{Sample Space := A set of all possible outcomes }$ \n",
    "\n",
    "$ F : \\text{Field of events := A collection of events }$ \n",
    "\n",
    "$\\text{ Probability function } P : F \\rightarrow \\mathbb{R} $\n",
    "\n",
    "$\\text{Random variable X := denotes a qunatity (discrete or contiuous) of some event that we don't know yet.}$\n",
    "\n",
    "**Personal Note:** <br> **I aim to write the random variables in CAPITAL to always remind myself that they can be any value until we assign a value in lower case <br> (in vector cases the difference will be clear as well).**\n",
    "\n",
    "\n",
    "\n",
    "| Component | **Discrete Example: Fair Coin Flip** | **Continuous Example: Person's Height** |\n",
    "|-----------|--------------------------------------|----------------------------------------|\n",
    "| **$\\Omega$** (Sample Space) | $\\{\\text{Heads}, \\text{Tails}\\}$ | $[0, \\infty)$ (all possible heights in meters) |\n",
    "| **$F$** (Field of Events) | $\\{\\emptyset, \\{\\text{Heads}\\}, \\{\\text{Tails}\\}, \\{\\text{Heads}, \\text{Tails}\\}\\}$ | Borel $\\sigma$-algebra on $[0, \\infty)$ (all measurable intervals) |\n",
    "| **$P$** (Probability Function) | $P(\\{\\text{Heads}\\}) = 0.5$ <br> $P(\\{\\text{Tails}\\}) = 0.5$ <br> $P(\\Omega) = 1$ | $P \\sim \\mathcal{N}(1.7, 0.1)$ <br> $P(X \\in [1.6, 1.8]) \\approx 0.68$ <br> $P(X = 1.75) = 0$ |\n",
    "| **$X$** (Random Variable) | $X = \\begin{cases} 1 & \\text{if Heads} \\\\ 0 & \\text{if Tails} \\end{cases}$ | $X : \\Omega \\rightarrow \\mathbb{R}$ <br> Maps outcomes to measured height |\n",
    "| **Key Property** | $P(X = 0) = 0.5$ (point probabilities exist) | $P(X = c) = 0$ for any specific $c$ (use intervals) |\n",
    "\n",
    "\n",
    "Consider the coin-flip example, if we don't know any information about the probabilities of landing head or tails we have but to experiment. <br>\n",
    "This is known as observing instances of a random variable. <br> The list of all the observed results is a $probability \\ distribution \\ Pr(X)$.\n",
    "\n",
    "\n",
    "- For a discrerte random variable we have: $Pr(X = k) \\in [0,1]$ where k is a possible outcome of event. <br>\n",
    "\n",
    "- For a continuous variable, we have $Pr(X = a) \\ge 0$ where each $a$ is mapable in the domain $X$ and the integral of this probability of this density function (PDF) over the domain $X$ is one.\n",
    "\n",
    "From now on we'll assume that we're dealing with **continous random variables**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cbd4ed",
   "metadata": {},
   "source": [
    "\n",
    "## Joint Probability and Conditional\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e9069e",
   "metadata": {},
   "source": [
    "\n",
    "### Joint Probability\n",
    "\n",
    "Suppose we have two random variables $X$ and $Y$. The $joint \\ distribution \\ Pr(X, Y)$ tells us about the natural tendency that $X$ and $Y$ will take on a specific combination of values. \n",
    "\n",
    "$$ \\boxed{\\int \\int Pr(X, Y)\\cdot dxdy = 1 }$$\n",
    "\n",
    "In some cases we can store multiple random variables in a vector $\\vec{x}$ so the joint distribution of the vector is $Pr(\\vec{x})$\n",
    "and similarly we can also have $Pr(\\vec{x}, \\vec{y})$\n",
    "\n",
    "### Marginalization\n",
    "\n",
    "If we're provided with $Pr(X, Y)$ over two random variables, we're able to recover the $marginal$ distributions $Pr(X)$ and $Pr(Y)$ by intergrating over the other variable. \n",
    "\n",
    "$$ \\boxed{ \\int Pr(X, Y) \\cdot dx = Pr(Y)}$$\n",
    "\n",
    "$$ \\boxed { \\int Pr(X, Y) \\cdot dy = Pr(X)}$$\n",
    "\n",
    "We're computing the disribution of one variable regardless of the value of the other variable. <br> This can extend to higher dimensions and the same process is applied.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6710d688",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Conditional Probability and Likelihood\n",
    "\n",
    "The $Conditional \\ probability \\ Pr(X | Y) $ is the probability of variable $X$ taking some value given a known value on $Y$. <br>\n",
    "NOTE: This definition does not assume causality or direction of influence between $X$ and $Y$.<br>\n",
    "- We could have $X = \\text{ \\# of heads landed}$ and $Y = \\text{ \\# of tails landed}$\n",
    "- We could have $X = \\text{ \\# of heads landed}$ and $Y = \\text{ \\# of passangers entering a bus in an hour}$\n",
    "$$ \\boxed{Pr(X | Y) = \\frac{Pr(X, Y)}{Pr(Y)} }$$\n",
    "\n",
    "$$ \\boxed{Pr(Y | X) = \\frac{Pr(X, Y)}{Pr(X)} }$$\n",
    "\n",
    "Read it as the \"The probability of X occuring (occuring means having some value) given Y occured is the probability of both X and Y occuring divided by the probabilty of Y occuring irrespective to X\"\n",
    "\n",
    "**Note: That we can obtain the conditional probability using the above joint proability formulation**\n",
    "\n",
    "\n",
    "### Chain Rule\n",
    "\n",
    "join probability of multiple events can be broken into conditional probabilities\n",
    "\n",
    "$$Pr(X_1, X_2) = Pr(X_2 | X_1) \\cdot Pr(X_1)$$\n",
    "\n",
    "$$Pr(X_1, X_2, X_3) = Pr(X_3 | X_2, X_1) \\cdot Pr(X_1, X_2) = Pr(X_3 | X_2, X_1) \\cdot Pr(X_2 | X_1) \\cdot Pr(X_1)$$\n",
    "\n",
    "$$Pr(X_1, X_2, X_3, X_4) = Pr(X_4 | X_3, X_2, X_1) \\cdot Pr(X_3, X_2, X_1) = Pr(X_4 | X_3, X_2, X_1) \\cdot Pr(X_3 | X_2, X_1) \\cdot P(X_2, X_1) = Pr(X_4 | X_3, X_2, X_1) \\cdot Pr(X_3 | X_2, X_1) \\cdot Pr(X_2 | X_1) \\cdot Pr(X_1)$$\n",
    "\n",
    "**General Explicit Form**\n",
    "$$\\boxed{Pr(X_1, X_2, \\ldots, X_n) = Pr(X_n | X_{n-1}, \\ldots, X_1) \\cdot Pr(X_{n-1} | X_{n-2}, \\ldots, X_1) \\cdots Pr(X_2 | X_1) \\cdot Pr(X_1)}$$\n",
    "\n",
    "**Compact Form**\n",
    "$$\\boxed{Pr(X_1, X_2, \\ldots, X_n) = \\prod_{i=1}^{n} Pr(X_i | X_{i-1}, \\ldots, X_1)}$$\n",
    "\n",
    "**Important Clarification:**\n",
    "\n",
    "The subscript order ($X_1, X_2, \\ldots, X_n$) is **purely notational** and does **not** imply:\n",
    "- ❌ Temporal ordering (events happening in sequence)\n",
    "- ❌ Causal relationships between variables\n",
    "- ❌ That $X_1$ must occur \"before\" $X_2$\n",
    "\n",
    "It's simply a **labeling convention** to systematically decompose the joint probability. We could equally write:\n",
    "$$Pr(X_3, X_1, X_2) = Pr(X_2 | X_3, X_1) \\cdot Pr(X_1 | X_3) \\cdot Pr(X_3)$$\n",
    "\n",
    "The ordering just needs to be consistent within the decomposition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc896bb",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Distinction between Likelihood and Conditional\n",
    "\n",
    "Suppose X: is our **data (observation/outcomes)**  <br>\n",
    "Suppose Y: is our **Prameters or model specification**\n",
    "\n",
    "##### Conditional Says $Pr(X| Y)$\n",
    "-  **We fix $Y$ and let $X$ vary:** \"Given these fixed parameters what are the chances of seeing different outcomes?\" \n",
    "-  This is a **Probability Density Function** or **Probability Mass Function**\n",
    "-  Since X represents all possible outcomes in the sample space IT MUST SUM (intergrate) TO 1.\n",
    "-  Example: You have a fair die the probability of rolling $\\{1, 2, 3, 4, 5, 6\\}$ is 1.\n",
    "\n",
    "##### Likelihood uses $Pr(X | Y)$ but interpreted as a function of $Y$\n",
    "- **We fix $X$ and let $Y$ vary:** “Given the observed outcome, how plausible are different parameter values?”\n",
    "- This is called the **Likelihood Function:** $L(Y \\mid X=x) \\;\\equiv\\; \\Pr(X=x \\mid Y)$\n",
    "- We're comparing different models/parameters against the **same observed data**\n",
    "- The likelihood is not a probability distribution over Y and therefore does not need to sum to 1\n",
    "- Example: After observing a roll of “6”, we can compare <br>\n",
    "$L(\\text{fair} \\mid 6) = \\Pr(6 \\mid \\text{fair}), \\quad\n",
    "L(\\text{weighted} \\mid 6) = \\Pr(6 \\mid \\text{weighted})$\n",
    "\n",
    "\n",
    "##### So why do conditional probability and likelihood use the same expression? \n",
    "##### A. Because they use the same mathematical quantity but with different variables fixed\n",
    "In the **Likelihood** when we say $Pr(X | Y)$  we're saying $Pr(X = x | Y = ?)$ view it as a function of $Y$ <br>\n",
    "In **Conditional** when we say $Pr(X | Y)$ we're saying $Pr(X = ? | Y = y)$ and view it as a function of $X$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9e48da",
   "metadata": {},
   "source": [
    "## Bayes' rule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55db991",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Given the above we can manipulate a few of the formulas: \n",
    "\n",
    "$$Pr(X, Y) = Pr(X | Y)Pr(Y) = Pr(Y | X)Pr(X)$$\n",
    "\n",
    "$$ \\downarrow $$\n",
    "\n",
    "$$\\boxed{Pr(X | Y) = \\frac{Pr(Y | X)Pr(X)}{Pr(Y)}}$$\n",
    "\n",
    "$Pr(X | Y) = \\textcolor{lightblue}{Posterior Probability}$ <br>\n",
    "$Pr(Y | X) = \\textcolor{lightblue}{Likelihood}$ <br>\n",
    "$Pr(X) = \\textcolor{lightblue}{Prior \\ Probability}$ <br>\n",
    "$Pr(Y) = \\textcolor{lightblue}{Evidence Probability}$ <br>\n",
    "\n",
    "$\\text{This equation maps what we know about } X \\text{ before observing } Y \\ Pr(X) \\text{ to the posterior } Pr(X | Y) \\text{ What we know about } X \\text{ after observing } Y$\n",
    "\n",
    "$\\text{This is important since it's an indication of how Y affected X}$\n",
    "\n",
    "\n",
    "### Independence\n",
    "\n",
    "If the value of the random variable $Y$ tells us nothing about $X$ **AND** vice-versa, we say that $X$ and $Y$ are $\\text{independent}$ thereby: \n",
    "\n",
    "$$Pr(Y|Y) = Pr(X)$$\n",
    "$$Pr(Y | X) = Pr(X)$$\n",
    "\n",
    "It means that the probability distributions $Pr(Y | X = •)$ will have the same value.\n",
    "<br>\n",
    "Indeed the same is applied over the distributions $Pr(X | Y = •)$ will have the same value.\n",
    "\n",
    "$$Pr(X, Y) = Pr(X | Y)Pr(Y) = Pr(X)Pr(Y)$$\n",
    "\n",
    "$$\\downarrow$$\n",
    "\n",
    "$$Pr(X, Y)  = Pr(X)Pr(Y)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481c8931",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f945df3a",
   "metadata": {},
   "source": [
    "## Maximum Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31569029",
   "metadata": {},
   "source": [
    "Until we've been holding this concept where the model (our function) produces a **direct** output $f[x, \\phi]$ (models prediction) based on the input $x$ and the parameters $\\phi$.<br>\n",
    "Let's change this perspective into a probabilitic one, where we actually consider the model computing a $\\text{Conditional Probability } Pr(Y | X)$ over the possible outputs $Y$ given the inputs $X$.<br>\n",
    "\n",
    "With this in mind the loss encourages each training output $Y_i$ to have a high probability under the distribution $Pr(Y_i | X_i)$ computed from the correcsponding input $X_i$.\n",
    "\n",
    "This is indeed the the likelihood as discussed above. \n",
    "\n",
    "|Example 1 | Example 2 | Example 3 | Example 4|\n",
    "|----------|-----------|-----------|----------|\n",
    "| <div align=\"center\"> <img  src=\"../images/chap4/regesLike.png\" alt=\"Linear Regression Distribution\" width=\"700\" /></div> | <div align=\"center\"> <img  src=\"../images/chap4/classifierLike.png\" alt=\"Discrete Distribution\" width=\"700\" /></div>| <div align=\"center\"> <img  src=\"../images/chap4/classfier2Like.png\" width=\"420\" /></div>|  <div align=\"center\"> <img  src=\"../images/chap4/contLike.png\" alt=\"ReLU Function\" width=\"700\" /></div>|\n",
    "|This is a regression problem where we want to predict $y \\in \\mathbb{R}$. <br> We look at the data and see what's the distribution and how \"likely\" is $Y = y$.| Here the task is to put in class $\\in \\{1, 2, 3, 4\\}$. Our data is discrete, <br>thus our distribution is in histogram form. <br> We ask the same question \"Given we have data $x$, looking at the distribution how 'likely' is $Y = y$.\" | This task predicts counts where our data is continuous $X \\in [0, 10]$. So we produce a histogram and see how likely given the data is it to predict $Y=y$. | This problem is a directional problem so $Y \\in (-\\pi, \\pi]$ and our data is also continuous $X \\in [0, 10]$.|\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b447f432",
   "metadata": {},
   "source": [
    "### How do we convert a model to compute probability distributions\n",
    "\n",
    "We need to choose a **parametric** distribution defined over the output domain $Y$. \n",
    "\n",
    "$$\\boxed{Pr(Y | \\theta)}$$\n",
    "\n",
    "Then we use the network to compute the parameters $\\theta$ of this distribution.\n",
    "\n",
    "For example if our output $Y \\in \\mathbb{R}$ then it may be suitable to choose the normal distribution. <br>\n",
    "The parameters that define it is the mean and variance. So we have $\\theta = \\{\\mu, \\sigma^2 \\}$.\n",
    "\n",
    "**Optimization point** <br>\n",
    "\n",
    "The model in this case only needs to learn the mean $\\mu$ since $\\sigma$ is derivable so technically $\\sigma^2$ could be treated as a constant.\n",
    "\n",
    "Below presents differrent Distributions for loss functions for different prediction goals.\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"../images/chap4/distrLoss.png\" width=\"700\" />\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f627da",
   "metadata": {},
   "source": [
    "### Maximum Likelihood Criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ac3794",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Our model for each training input now looks like this: $$\\theta_i  = f[x_i, \\phi]$$ \n",
    "\n",
    "Each observed training output $y_i$ should have a high probability under the corresponding disribution $Pr(y_i | \\theta_i)$.<br>\n",
    "\n",
    "So we'd want to choose the paramters which produces the maxmimum distribution of prediction over all predictions.\n",
    "\n",
    "$$ \n",
    "\\begin{align} \n",
    "\\hat{\\phi} &= \\mathbf{argmax}_{\\phi}\\big[ Pr(y_1, y_2, \\dots, y_N | x_1, x_2, \\dots, x_N ) \\big] \\\\ \n",
    "& \\Downarrow \\ i.i.d \\ (Independent \\ and \\ Identically \\ Distributed) \\\\\n",
    " &= \\mathbf{argmax}_{\\phi}\\big[\\ \\prod_{i=1}^N Pr(y_i | x_i) \\big] \\\\\n",
    "&= \\mathbf{argmax}_{\\phi}\\big[\\prod_{i=1}^N Pr(y_i | \\theta_i) \\big ] \\\\\n",
    "&= \\mathbf{argmax}_{\\phi}\\big[\\prod_{i=1}^N Pr(y_i | f[x_i, \\theta]) \\big ]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "This is known as the $\\textcolor{lightblue}{Maximum \\ Likelihood \\ Criterion}$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199ec859",
   "metadata": {},
   "source": [
    "### Maximizing log-Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f6038e",
   "metadata": {},
   "source": [
    "Note that we're dealing with a product of probabilities this can lead to two main issues.\n",
    "\n",
    "1. Theoretical – If the number of samples is large enough this can converge to 0. $^*$ \n",
    "2. Implentation – We only have so much degree of accuracy we can keep track of on a computer.\n",
    "\n",
    "Fortunately $\\log$ will help us here. This function ensures that no information is lost $^*$. We now see why this function helps our problem.\n",
    "\n",
    "$$\n",
    "\\begin{align} \n",
    "\\hat{\\phi} \n",
    "&= \\mathbf{argmax}_{\\phi}\\left[\\prod_{i=1}^N Pr(y_i | f[x_i, \\phi]) \\right] \\\\\n",
    "&= \\mathbf{argmax}_{\\phi}\\left[ \\log \\left( \\prod_{i=1}^N Pr(y_i | f[x_i, \\phi]) \\right) \\right] \\\\\n",
    "&= \\mathbf{argmax}_{\\phi}\\left[ \\sum_{i=1}^N \\log \\left(Pr(y_i | f[x_i, \\phi]) \\right) \\right]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "This resolves the finite prescision problem we had with the product.\n",
    "\n",
    "$^{*\\text{For the curious, the proof is located in the proof directory}}$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2212faf2",
   "metadata": {},
   "source": [
    "### Minimizing negative log-likelihoood\n",
    "\n",
    "Note that in ML aim to **Minimize** the loss we therefore flip:\n",
    "\n",
    "$$\n",
    "\\begin{align} \n",
    "\\hat{\\phi} \n",
    "&= \\mathbf{argmin}_{\\phi}\\left[ -\\sum_{i=1}^N \\log \\left(Pr(y_i | f[x_i, \\phi]) \\right) \\right] \\\\\n",
    "&= \\mathbf{argmin}_{\\phi}\\big[ L[\\phi] \\big]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "This forms the Final Loss function $L[\\phi]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4449c87a",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11237d3",
   "metadata": {},
   "source": [
    "Since our model now predicts a probability distribution over possible $y$ to perform an inference we need to extract ther maximum of the distribution. \n",
    "\n",
    "$$\\boxed{\\hat{y} = \\argmax_{y}\\big[Pr(y | f[x, \\hat{\\phi}]\\big]}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec382817",
   "metadata": {},
   "source": [
    "## Method: Constructing loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672aa06b",
   "metadata": {},
   "source": [
    "$$\\boxed{\\begin{aligned}\n",
    "&1. \\text{ Given the output choose a suitable probability distribution } Pr(y | \\theta) \\text{ defined over the domain of predictions} \\\\\n",
    "\\\\\n",
    "&2. \\text{ Set the ML model } f[x, \\phi] \\text{ to predict all independant parameters } \\\\\n",
    "&\\quad \\text{(and compute the rest of the parameters based on what's learnt) so } \\theta = f[x, \\phi] \\text{ and } Pr(y | \\theta) = Pr(y | f[x, \\phi]) \\\\\n",
    "\\\\\n",
    "&3. \\text{ We train the model to find the network parameters } \\hat{\\phi} \\text{ that minimizes the negative log-likelihood} \\\\\n",
    "&\\quad \\text{over the training dataset } \\{x_i, y_i\\}_{i=1}^N \\\\\n",
    "\\\\\n",
    "&4. \\text{ When needed to perform the inference we'll apply the argmax of the distribution } Pr(y | f[x, \\hat{\\phi}])\n",
    "\\end{aligned}}$$"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
