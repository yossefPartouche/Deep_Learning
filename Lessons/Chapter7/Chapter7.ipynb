{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a9486ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BiasVar import BiasVarianceVisualizer\n",
    "\n",
    "visualizer = BiasVarianceVisualizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61100d5e",
   "metadata": {},
   "source": [
    "# Sources of Error and HPO\n",
    "\n",
    "In this chapter we'll see that a well trained model could still exhibit generalisation errors:\n",
    "-  We'll understand the main sources of these errors.\n",
    "-  We'll Discuss Hyper-parameter Optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f94b191",
   "metadata": {},
   "source": [
    "## MNIST-1D Dataset Overview\n",
    "\n",
    "For this chapter, we'll use the **MNIST-1D dataset** — a simplified 1D version of the classic MNIST handwritten digit dataset.\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-between; gap: 20px;\">\n",
    "\n",
    "<div style=\"flex: 1;\">\n",
    "\n",
    "### Dataset Characteristics\n",
    "\n",
    "| **Property** | **Value** | **Description** |\n",
    "|--------------|-----------|-----------------|\n",
    "| **Classes** | 10 | Digits 0–9 (i.e., $y \\in \\{0, 1, 2, \\ldots, 9\\}$) |\n",
    "| **Training samples** | 4,000 | Total examples ($I = 4000$) |\n",
    "| **Class distribution** | ~400 per class | Uniformly distributed (balanced dataset) |\n",
    "| **Input dimensions** | 40 | Each $\\mathbf{x}_i \\in \\mathbb{R}^{40}$ is a **synthetically generated** 1D signal (not derived from 2D images) |\n",
    "| **Data generation** | Template-based | Created from scratch using:<br>1. Hand-crafted 1D template curves for each digit<br>2. Random transformations (shift, scale, pad)<br>3. Additive noise |\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"flex: 1;\">\n",
    "\n",
    "### Training Configuration\n",
    "\n",
    "| **Hyperparameter** | **Value** | **Explanation** |\n",
    "|--------------------|-----------|-----------------|\n",
    "| **Optimizer** | SGD | Stochastic Gradient Descent |\n",
    "| **Batch size** | 100 | Samples per gradient update |\n",
    "| **Learning rate** | 0.1 | Step size for parameter updates |\n",
    "| **Total steps** | 6,000 | Number of gradient updates |\n",
    "| **Epochs** | 150 | Full passes through data<br>($6000 \\times 100 / 4000 = 150$) |\n",
    "| **Loss function** | Cross-Entropy | Multiclass classification loss |\n",
    "\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "### Model Architecture\n",
    "\n",
    "We use a **fully connected neural network** with the following structure:\n",
    "\n",
    "<img src=\"../Lessons/images/chap7/MNIST_net.png\" width=\"900\" />\n",
    "</div>\n",
    "\n",
    "**Total parameters:** $(40 \\times 100) + 100 + (100 \\times 100) + 100 + (100 \\times 10) + 10 = 15{,}210$\n",
    "\n",
    "### Observations \n",
    "\n",
    "After 4000 steps, the training data classified are perfectly classified. \n",
    "The training loss deceases eventually approaching 0.\n",
    "\n",
    "**Our Testing Data**\n",
    "Generated another 1000 more examples using the same process.\n",
    "The data decreases as the training proceeds but down to 40%. \n",
    "This is an imporovement of \"guessing\" the classifer but is far from the training data. \n",
    "\n",
    "---\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8b2695",
   "metadata": {},
   "source": [
    "## Sources of Error\n",
    "\n",
    "To visualize why models fail to generalize, we analyze a **1D least squares regression problem** where the data generation process is fully known.\n",
    "\n",
    "**1. The Ground Truth (Data Generation)**\n",
    "We generate training and test data by sampling inputs $x \\in [0,1]$, passing them through a quasi-sinusoidal function, and adding fixed Gaussian noise:\n",
    "$$y_{\\text{true}} = A\\sin(\\phi_0 + \\phi_1 x) + \\epsilon, \\quad \\text{where } \\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$$\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"../Lessons/images/chap7/Modelfunc.png\" width=\"400\" />\n",
    "<img src=\"../Lessons/images/chap7/sinusModel.png\" width=\"538\" />\n",
    "</div>\n",
    "\n",
    "\n",
    "**2. The Model (Approximation)**\n",
    "We fit this data using a simplified shallow neural network with $D$ hidden units.\n",
    "* **Structure:** It forms a piecewise linear function with \"joints\" evenly spaced at intervals of $1/D$.\n",
    "* **Optimization:** This specific architecture allows for a **closed-form solution**, guaranteeing we find the global minimum of the Mean Squared Error (MSE) loss:\n",
    "    $$L[\\phi] = \\sum_{i=1}^N(f[x_i, \\phi] - y_i)^2$$\n",
    "\n",
    "By eliminating optimization uncertainty (since we find the global minimum), we can isolate and analyze the theoretical sources of error strictly arising from the model's capacity and the data itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212e397f",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "### Three Sources of Generalization Error\n",
    "\n",
    "</div>\n",
    "\n",
    "| | **Noise (Irreducible Error)** | **Bias (Model Rigidity)** | **Variance (Model Sensitivity)** |\n",
    "|---|---|---|---|\n",
    "| **Definition** | Random error inherent in the data generation process | Systematic error from insufficient model complexity | Error from model's sensitivity to specific training data |\n",
    "| **Cause** | Random noise in data:<br>• Stochastic processes<br>• Mislabeling<br>• Unobserved variables | Model architecture cannot capture true function's complexity | Limited training data prevents distinguishing signal from noise |\n",
    "| **Example** | Multiple valid outputs $y$ for same input $x$ due to $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$ | Piecewise linear model with 3 segments cannot fit smooth sine curve | Model fits training noise, produces different results with different data samples |\n",
    "| **Can be reduced by...** | ❌ **Cannot be reduced**<br>(intrinsic to problem) | ✅ Increasing model capacity<br>(more hidden units, deeper networks) | ✅ More training data<br>✅ Regularization<br>✅ Ensemble methods |\n",
    "| **Training performance** | ✅ Can achieve 0 training error<br>(by memorizing noise) | ❌ Cannot achieve 0 training error<br>(structural limitation) | ✅ Can achieve 0 training error<br>(overfitting) |\n",
    "| **Test performance** | ❌ Always contributes to test error | ❌ Contributes when model too simple<br>(**underfitting**) | ❌ Contributes when model too flexible<br>(**overfitting**) |\n",
    "| **Mathematical representation** | $\\mathbb{E}[(y - \\mathbb{E}[y\\|x])^2]$ | $\\mathbb{E}[(\\mathbb{E}[\\hat{f}(x)] - f^*(x))^2]$ | $\\mathbb{E}[(\\hat{f}(x) - \\mathbb{E}[\\hat{f}(x)])^2]$ |\n",
    "| **Also known as** | Bayes error, aleatoric uncertainty | Approximation error, underfitting | Estimation error, overfitting |\n",
    "| **Images** |  <img src=\"../images/chap7/sinusNoise.png\" width=\"450\" /> | <img src=\"../images/chap7/sinusBias.png\" width=\"350\" /> | <img src=\"../images//chap7/sinusVar.png\" width=\"350\" /> |\n",
    "\n",
    "\n",
    "\n",
    "**Key insight:** Total test error = Noise + Bias² + Variance\n",
    "\n",
    "The mathematical formulation of the total test error is located in proof directory\n",
    "\n",
    "- **Noise** is unavoidable\n",
    "- **Bias** decreases as model complexity increases\n",
    "- **Variance** increases as model complexity increases\n",
    "\n",
    "This creates the **bias-variance tradeoff** — the central challenge in model selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc93791",
   "metadata": {},
   "source": [
    "## Reducing Error "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d4e79d",
   "metadata": {},
   "source": [
    "### Reducing Variance \n",
    "\n",
    "Variance emerges when a model is overly sensitive to the specific training data it sees. This happens due to:\n",
    "\n",
    "1. **Limited data**: Insufficient samples prevent the model from learning the true underlying pattern\n",
    "2. **Noisy data**: Random fluctuations in training examples are mistaken for signal\n",
    "3. **Sparse coverage**: Data concentrated in specific regions of the input space, leaving other regions poorly characterized\n",
    "\n",
    "**Solutions:**\n",
    "- **More training data**: Averaging over more examples helps distinguish true signal from noise\n",
    "- **Better data coverage**: Ensuring samples are well-distributed across the input space\n",
    "- **Regularization**: Constraining model complexity (e.g., L2 penalty, dropout)\n",
    "- **Ensemble methods**: Averaging predictions from multiple models trained on different data subsets\n",
    "- **Early stopping**: Preventing the model from fitting training noise\n",
    "- **Data augmentation**: Artificially expanding the training set with transformed examples\n",
    "\n",
    "When a model has high variance, it will fit the training data extremely well but perform poorly on unseen test data — this is **overfitting**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0649c938",
   "metadata": {},
   "source": [
    "### Reducing Bias\n",
    "\n",
    "Bias emerges when a model lacks the expressiveness to capture the true underlying pattern in the data. This happens due to:\n",
    "\n",
    "1. **Insufficient model capacity**: The architecture has too few parameters or layers to represent complex functions\n",
    "2. **Wrong model family**: Using a model class fundamentally unsuited to the problem (e.g., linear models for non-linear data)\n",
    "3. **Overly restrictive assumptions**: Imposing constraints that exclude the true data-generating function\n",
    "\n",
    "**Solutions:**\n",
    "- **Increase model capacity**: Add more hidden units, layers, or parameters\n",
    "- **Use more expressive architectures**: Switch to models with greater representational power (e.g., from linear to neural networks)\n",
    "- **Feature engineering**: Create more informative input representations\n",
    "- **Remove unnecessary constraints**: Reduce regularization if it's too strong\n",
    "- **Ensemble of diverse models**: Combine predictions from different model families\n",
    "\n",
    "**Theoretical foundation**: The Universal Approximation Theorem guarantees that sufficiently wide neural networks can approximate any continuous function arbitrarily well.\n",
    "\n",
    "When a model has high bias, it will perform poorly on both training and test data — this is **underfitting**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98807b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31546f07172a402f92812d12adcdebbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=3, continuous_update=False, description='Complexity:', max=20, min=1), F…"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualizer.interactive_plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
